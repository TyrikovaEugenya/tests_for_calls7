"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–±–æ—Ä–∞ –≤—Å–µ—Ö URL —Å—Ç—Ä–∞–Ω–∏—Ü —Ñ–∏–ª—å–º–æ–≤ –Ω–∞ calls7.com
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–∞–≥–∏–Ω–∞—Ü–∏—é —á–µ—Ä–µ–∑ ?offset=...&limit=...
–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ URL –≤ films.json –∏ films.txt
"""

import json
import time
from pathlib import Path
from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeoutError


def collect_film_urls(
    base_url: str = "https://calls7.com",
    limit: int = 100,
    max_pages: int = 200,  # ~20 000 —Å—Ç—Ä–∞–Ω–∏—Ü –º–∞–∫—Å–∏–º—É–º
    output_dir: str = "data"
) -> list:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ URL —Ñ–∏–ª—å–º–æ–≤ —Å calls7.com —á–µ—Ä–µ–∑ –ø–∞–≥–∏–Ω–∞—Ü–∏—é.
    
    :param base_url: –±–∞–∑–æ–≤—ã–π URL
    :param limit: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏–ª—å–º–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ (–º–∞–∫—Å. 100)
    :param max_pages: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –æ–±—Ö–æ–¥–∞
    :param output_dir: –ø–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    :return: —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö URL
    """
    print(f"üöÄ –°–±–æ—Ä URL —Ñ–∏–ª—å–º–æ–≤ —Å {base_url} (limit={limit})...")
    film_urls = set()
    total_scraped = 0

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()

        for page_num in range(max_pages):
            offset = page_num * limit
            url = f"{base_url}/?offset={offset}&limit={limit}"
            print(f"  üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num + 1} ({offset}-{offset + limit}): {url}")

            try:
                page.goto(url, timeout=30000)
                page.wait_for_load_state("networkidle", timeout=30000)

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ñ–∏–ª—å–º—ã —á–µ—Ä–µ–∑ JS (–Ω–∞–¥—ë–∂–Ω–µ–µ, —á–µ–º CSS)
                # –ò—â–µ–º —Å—Å—ã–ª–∫–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ /movie/, /kvest/, /chernyy-zamok/, /mara/, /calls7/
                urls = page.evaluate("""() => {
                    return Array.from(document.querySelectorAll('.movie-card[data-url]'))
                        .map(el => el.getAttribute('data-url'))
                        .filter(Boolean)
                        .map(slug => {
                            const url = new URL(slug, document.baseURI);
                            url.search = '';
                            url.hash = '';
                            return url.href;
                        });
                }""")

                new_urls = [u for u in urls if u not in film_urls]
                film_urls.update(urls)
                total_scraped += len(new_urls)

                print(f"    ‚ûï –ù–∞–π–¥–µ–Ω–æ: {len(new_urls)} –Ω–æ–≤—ã—Ö URL (–≤—Å–µ–≥–æ: {len(film_urls)})")

                # –ï—Å–ª–∏ –Ω–æ–≤—ã—Ö URL –Ω–µ—Ç ‚Äî –≤—ã—Ö–æ–¥–∏–º
                if len(new_urls) == 0 and page_num > 0:
                    print("    üõë –ù–æ–≤—ã–µ —Ñ–∏–ª—å–º—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã ‚Äî –∑–∞–≤–µ—Ä—à–∞–µ–º –ø–∞–≥–∏–Ω–∞—Ü–∏—é.")
                    break

                # –ó–∞—â–∏—Ç–∞ –æ—Ç rate-limit
                time.sleep(0.5)

            except PlaywrightTimeoutError:
                print(f"    ‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {url} ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                break
            except Exception as e:
                print(f"    ‚ùå –û—à–∏–±–∫–∞: {e}")
                break

        browser.close()

    print(f"\n‚úÖ –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö URL: {len(film_urls)}")
    return sorted(film_urls)


def save_results(film_urls: list, output_dir: str = "data"):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON –∏ TXT."""
    Path(output_dir).mkdir(exist_ok=True)

    # JSON ‚Äî –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    json_path = Path(output_dir) / "films.json"
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump({
            "total": len(film_urls),
            "urls": film_urls,
            "source": "calls7.com",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }, f, indent=2, ensure_ascii=False)
    print(f"üìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {json_path}")

    # TXT ‚Äî –¥–ª—è —á–µ–ª–æ–≤–µ–∫–∞ / grep / CI
    txt_path = Path(output_dir) / "films.txt"
    with open(txt_path, "w", encoding="utf-8") as f:
        for url in film_urls:
            f.write(url + "\n")
    print(f"üìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {txt_path}")


if __name__ == "__main__":
    urls = collect_film_urls(
        base_url="https://calls7.com",
        limit=100,          # –º–∞–∫—Å–∏–º—É–º, –∫–æ—Ç–æ—Ä—ã–π —Å–∞–π—Ç –ø—Ä–∏–Ω–∏–º–∞–µ—Ç
        max_pages=200       # ~20 000 —Å—Ç—Ä–∞–Ω–∏—Ü
    )
    save_results(urls, output_dir="data")

    # –ü—Ä–∏–º–µ—Ä –ø–µ—Ä–≤—ã—Ö 5
    print("\nüìã –ü—Ä–∏–º–µ—Ä—ã URL:")
    for url in urls[:5]:
        print(f"  - {url}")